{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBAC - Regressão II - regressão múltipla\n",
    "\n",
    "## Tarefa I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previsão de renda II\n",
    "\n",
    "Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que é a base do seu próximo projeto. Vamos usar os recursos que vimos até aqui nesta base.\n",
    "\n",
    "|variavel|descrição|\n",
    "|-|-|\n",
    "|data_ref                | Data de referência de coleta das variáveis |\n",
    "|index                   | Código de identificação do cliente|\n",
    "|sexo                    | Sexo do cliente|\n",
    "|posse_de_veiculo        | Indica se o cliente possui veículo|\n",
    "|posse_de_imovel         | Indica se o cliente possui imóvel|\n",
    "|qtd_filhos              | Quantidade de filhos do cliente|\n",
    "|tipo_renda              | Tipo de renda do cliente|\n",
    "|educacao                | Grau de instrução do cliente|\n",
    "|estado_civil            | Estado civil do cliente|\n",
    "|tipo_residencia         | Tipo de residência do cliente (própria, alugada etc)|\n",
    "|idade                   | Idade do cliente|\n",
    "|tempo_emprego           | Tempo no emprego atual|\n",
    "|qt_pessoas_residencia   | Quantidade de pessoas que moram na residência|\n",
    "|renda                   | Renda em reais|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression  # Adicione esta linha\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('previsao_de_renda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             15000 non-null  int64  \n",
      " 1   data_ref               15000 non-null  object \n",
      " 2   id_cliente             15000 non-null  int64  \n",
      " 3   sexo                   15000 non-null  object \n",
      " 4   posse_de_veiculo       15000 non-null  bool   \n",
      " 5   posse_de_imovel        15000 non-null  bool   \n",
      " 6   qtd_filhos             15000 non-null  int64  \n",
      " 7   tipo_renda             15000 non-null  object \n",
      " 8   educacao               15000 non-null  object \n",
      " 9   estado_civil           15000 non-null  object \n",
      " 10  tipo_residencia        15000 non-null  object \n",
      " 11  idade                  15000 non-null  int64  \n",
      " 12  tempo_emprego          12427 non-null  float64\n",
      " 13  qt_pessoas_residencia  15000 non-null  float64\n",
      " 14  renda                  15000 non-null  float64\n",
      "dtypes: bool(2), float64(3), int64(4), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
    "2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?\n",
    "3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?\n",
    "4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?\n",
    "5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?\n",
    "6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n",
    "7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina a fração de dados que você deseja para o conjunto de teste (25% neste caso)\n",
    "test_size = 0.25\n",
    "\n",
    "# Use a função train_test_split para dividir os dados em treinamento e teste\n",
    "train_df, test_df = train_test_split(df, test_size=test_size, random_state=42)\n",
    "\n",
    "# O conjunto de treinamento estará em train_df e o conjunto de teste estará em test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 0\n",
      "Melhor R²: 0.2626387765366982\n"
     ]
    }
   ],
   "source": [
    "# Carregue os dados\n",
    "df = pd.read_csv('previsao_de_renda.csv')\n",
    "\n",
    "# Lidar com variáveis categóricas usando codificação de rótulos\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['sexo', 'tipo_renda', 'educacao', 'estado_civil', 'tipo_residencia']\n",
    "for col in categorical_columns:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Converter a coluna 'data_ref' em uma representação numérica (por exemplo, dias desde uma data de referência)\n",
    "df['data_ref'] = (pd.to_datetime(df['data_ref']) - pd.to_datetime('2000-01-01')).dt.days\n",
    "\n",
    "# Separar os dados em características (X) e alvo (y)\n",
    "X = df.drop(columns=['renda'])\n",
    "y = df['renda']\n",
    "\n",
    "# Tratar valores ausentes (NaN) usando imputação\n",
    "imputer = SimpleImputer(strategy='mean')  # Substituir NaNs pela média dos valores existentes\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste (25% para teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Definir os valores de alpha que você deseja testar\n",
    "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "# Criar uma lista para armazenar os resultados de R²\n",
    "r2_scores = []\n",
    "\n",
    "# Iterar pelos diferentes valores de alpha e ajustar o modelo Ridge\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    \n",
    "    # Fazer previsões no conjunto de teste\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    \n",
    "    # Calcular o R² e armazená-lo na lista\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# Encontrar o valor de alpha que resultou no melhor R²\n",
    "best_alpha = alphas[r2_scores.index(max(r2_scores))]\n",
    "best_r2 = max(r2_scores)\n",
    "\n",
    "print(f\"Melhor valor de alpha: {best_alpha}\")\n",
    "print(f\"Melhor R²: {best_r2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samwalford/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/samwalford/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samwalford/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.884e+11, tolerance: 7.723e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samwalford/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.884e+11, tolerance: 7.723e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samwalford/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.884e+11, tolerance: 7.723e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samwalford/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.884e+11, tolerance: 7.723e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/samwalford/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.883e+11, tolerance: 7.723e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha para Lasso: 0.1\n",
      "Melhor R² para Lasso: 0.26263986198736244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samwalford/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.881e+11, tolerance: 7.723e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Carregue os dados\n",
    "df = pd.read_csv('previsao_de_renda.csv')\n",
    "\n",
    "# Lidar com variáveis categóricas usando codificação de rótulos\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['sexo', 'tipo_renda', 'educacao', 'estado_civil', 'tipo_residencia']\n",
    "for col in categorical_columns:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Converter a coluna 'data_ref' em uma representação numérica (por exemplo, dias desde uma data de referência)\n",
    "df['data_ref'] = (pd.to_datetime(df['data_ref']) - pd.to_datetime('2000-01-01')).dt.days\n",
    "\n",
    "# Separar os dados em características (X) e alvo (y)\n",
    "X = df.drop(columns=['renda'])\n",
    "y = df['renda']\n",
    "\n",
    "# Tratar valores ausentes (NaN) usando imputação\n",
    "imputer = SimpleImputer(strategy='mean')  # Substituir NaNs pela média dos valores existentes\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste (25% para teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Definir os valores de alpha que você deseja testar\n",
    "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "# Crie uma lista para armazenar os resultados de R² para Lasso\n",
    "r2_scores_lasso = []\n",
    "\n",
    "# Iterar pelos diferentes valores de alpha e ajustar o modelo Lasso\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    \n",
    "    # Fazer previsões no conjunto de teste\n",
    "    y_pred = lasso.predict(X_test)\n",
    "    \n",
    "    # Calcular o R² e armazená-lo na lista\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores_lasso.append(r2)\n",
    "\n",
    "# Encontrar o valor de alpha que resultou no melhor R² para Lasso\n",
    "best_alpha_lasso = alphas[r2_scores_lasso.index(max(r2_scores_lasso))]\n",
    "best_r2_lasso = max(r2_scores_lasso)\n",
    "\n",
    "print(f\"Melhor valor de alpha para Lasso: {best_alpha_lasso}\")\n",
    "print(f\"Melhor R² para Lasso: {best_r2_lasso}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in ./anaconda3/lib/python3.11/site-packages (0.23.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in ./anaconda3/lib/python3.11/site-packages (from mlxtend) (1.11.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in ./anaconda3/lib/python3.11/site-packages (from mlxtend) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in ./anaconda3/lib/python3.11/site-packages (from mlxtend) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in ./anaconda3/lib/python3.11/site-packages (from mlxtend) (1.3.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in ./anaconda3/lib/python3.11/site-packages (from mlxtend) (3.7.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in ./anaconda3/lib/python3.11/site-packages (from mlxtend) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->mlxtend) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² na base de teste após seleção de recursos stepwise: 0.14114639596819656\n"
     ]
    }
   ],
   "source": [
    "# Carregue os dados\n",
    "df = pd.read_csv('previsao_de_renda.csv')\n",
    "\n",
    "# Lidar com variáveis categóricas usando codificação de rótulos\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['sexo', 'tipo_renda', 'educacao', 'estado_civil', 'tipo_residencia']\n",
    "for col in categorical_columns:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Converter a coluna 'data_ref' em uma representação numérica (por exemplo, dias desde uma data de referência)\n",
    "df['data_ref'] = (pd.to_datetime(df['data_ref']) - pd.to_datetime('2000-01-01')).dt.days\n",
    "\n",
    "# Separar os dados em características (X) e alvo (y)\n",
    "X = df.drop(columns=['renda'])\n",
    "y = df['renda']\n",
    "\n",
    "# Tratar valores ausentes (NaN) usando imputação\n",
    "imputer = SimpleImputer(strategy='mean')  # Substituir NaNs pela média dos valores existentes\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste (25% para teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Inicializar um modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "\n",
    "# Inicializar o sequencial feature selector para seleção de recursos stepwise\n",
    "sfs = SequentialFeatureSelector(model, forward=True, scoring='r2', cv=5)\n",
    "\n",
    "# Realizar seleção de recursos stepwise no conjunto de treinamento\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "# Obter o índice das características selecionadas\n",
    "selected_features_idx = sfs.k_feature_idx_\n",
    "\n",
    "# Selecionar as características correspondentes no conjunto de teste\n",
    "X_test_selected = X_test[:, selected_features_idx]\n",
    "\n",
    "# Treinar o modelo usando as características selecionadas\n",
    "model.fit(X_train[:, selected_features_idx], y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test_selected)\n",
    "\n",
    "# Calcular o R²\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"R² na base de teste após seleção de recursos stepwise: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² para Ridge: 0.26263874793913045\n",
      "R² para Lasso: 0.26263844994183194\n",
      "R² para Stepwise: 0.14114639596819656\n",
      "Número de recursos selecionados pelo modelo stepwise: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samwalford/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.884e+11, tolerance: 7.723e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Carregue os dados\n",
    "df = pd.read_csv('previsao_de_renda.csv')\n",
    "\n",
    "# Lidar com variáveis categóricas usando codificação de rótulos\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['sexo', 'tipo_renda', 'educacao', 'estado_civil', 'tipo_residencia']\n",
    "for col in categorical_columns:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Converter a coluna 'data_ref' em uma representação numérica (por exemplo, dias desde uma data de referência)\n",
    "df['data_ref'] = (pd.to_datetime(df['data_ref']) - pd.to_datetime('2000-01-01')).dt.days\n",
    "\n",
    "# Separar os dados em características (X) e alvo (y)\n",
    "X = df.drop(columns=['renda'])\n",
    "y = df['renda']\n",
    "\n",
    "# Tratar valores ausentes (NaN) usando imputação\n",
    "imputer = SimpleImputer(strategy='mean')  # Substituir NaNs pela média dos valores existentes\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste (25% para teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Inicializar modelos Ridge e Lasso\n",
    "ridge_model = Ridge(alpha=0.01)  # Escolha o alpha adequado\n",
    "lasso_model = Lasso(alpha=0.01)  # Escolha o alpha adequado\n",
    "\n",
    "# Treinar modelos Ridge e Lasso\n",
    "ridge_model.fit(X_train, y_train)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Calcular o R² para modelos Ridge e Lasso na base de teste\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "# Inicializar o sequencial feature selector para seleção de recursos stepwise\n",
    "sfs = SequentialFeatureSelector(LinearRegression(), forward=True, scoring='r2', cv=5)\n",
    "\n",
    "# Realizar seleção de recursos stepwise no conjunto de treinamento\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "# Obter o índice das características selecionadas\n",
    "selected_features_idx = sfs.k_feature_idx_\n",
    "\n",
    "# Selecionar as características correspondentes no conjunto de teste\n",
    "X_test_selected = X_test[:, selected_features_idx]\n",
    "\n",
    "# Treinar um modelo de regressão linear com as características selecionadas\n",
    "model_stepwise = LinearRegression()\n",
    "model_stepwise.fit(X_train[:, selected_features_idx], y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste usando o modelo stepwise\n",
    "y_pred_stepwise = model_stepwise.predict(X_test_selected)\n",
    "\n",
    "# Calcular o R² para o modelo stepwise na base de teste\n",
    "r2_stepwise = r2_score(y_test, y_pred_stepwise)\n",
    "\n",
    "# Número de recursos selecionados pelo modelo stepwise\n",
    "num_selected_features = len(selected_features_idx)\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(f\"R² para Ridge: {r2_ridge}\")\n",
    "print(f\"R² para Lasso: {r2_lasso}\")\n",
    "print(f\"R² para Stepwise: {r2_stepwise}\")\n",
    "print(f\"Número de recursos selecionados pelo modelo stepwise: {num_selected_features}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qual método chega a um melhor resultado?\n",
    " \n",
    "Com base nos resultados de R² na base de teste, tanto Ridge quanto Lasso parecem oferecer um desempenho semelhante e superior ao modelo de seleção de recursos stepwise. A escolha entre Ridge e Lasso depende da importância da interpretabilidade (Ridge) e da seleção automática de características (Lasso) para o seu problema específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² com transformação polinomial: 0.3757186172897421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samwalford/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=7.36541e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "# Carregue os dados\n",
    "df = pd.read_csv('previsao_de_renda.csv')\n",
    "\n",
    "# Lidar com variáveis categóricas usando codificação de rótulos\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['sexo', 'tipo_renda', 'educacao', 'estado_civil', 'tipo_residencia']\n",
    "for col in categorical_columns:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Converter a coluna 'data_ref' em uma representação numérica (por exemplo, dias desde uma data de referência)\n",
    "df['data_ref'] = (pd.to_datetime(df['data_ref']) - pd.to_datetime('2000-01-01')).dt.days\n",
    "\n",
    "# Separar os dados em características (X) e alvo (y)\n",
    "X = df.drop(columns=['renda'])\n",
    "y = df['renda']\n",
    "\n",
    "# Tratar valores ausentes (NaN) usando imputação\n",
    "imputer = SimpleImputer(strategy='mean')  # Substituir NaNs pela média dos valores existentes\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste (25% para teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Pipeline para aplicar transformação polinomial e treinar o modelo Ridge\n",
    "polynomial_pipe = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2)),  # Grau 2 para características polinomiais\n",
    "    ('ridge', Ridge(alpha=0.01))  # Ajuste o valor de alpha conforme necessário\n",
    "])\n",
    "\n",
    "# Treinar o modelo no conjunto de treinamento\n",
    "polynomial_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = polynomial_pipe.predict(X_test)\n",
    "\n",
    "# Calcular o R²\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"R² com transformação polinomial: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² com árvore de regressão: 0.15891218627802595\n"
     ]
    }
   ],
   "source": [
    "# Carregue os dados\n",
    "df = pd.read_csv('previsao_de_renda.csv')\n",
    "\n",
    "# Lidar com variáveis categóricas usando codificação de rótulos\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['sexo', 'tipo_renda', 'educacao', 'estado_civil', 'tipo_residencia']\n",
    "for col in categorical_columns:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Converter a coluna 'data_ref' em uma representação numérica (por exemplo, dias desde uma data de referência)\n",
    "df['data_ref'] = (pd.to_datetime(df['data_ref']) - pd.to_datetime('2000-01-01')).dt.days\n",
    "\n",
    "# Separar os dados em características (X) e alvo (y)\n",
    "X = df.drop(columns=['renda'])\n",
    "y = df['renda']\n",
    "\n",
    "# Tratar valores ausentes (NaN) usando imputação\n",
    "imputer = SimpleImputer(strategy='mean')  # Substituir NaNs pela média dos valores existentes\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste (25% para teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Inicializar um modelo de árvore de regressão\n",
    "tree_model = DecisionTreeRegressor(random_state=42)  # Você pode ajustar hiperparâmetros conforme necessário\n",
    "\n",
    "# Treinar o modelo\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Calcular o R²\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"R² com árvore de regressão: {r2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
